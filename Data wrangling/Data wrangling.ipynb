{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook I will perform some Datawrangling using Python API of Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data is obtained from MovieLens can be found here https://grouplens.org/datasets/movielens/25m/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import findspark to run spark on local mode in windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Spark Session from Pyspark.sql to create well a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Movie lens data wrangling\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the spark session up and running we can read the files, the files are in csv format (comma separated) where comma are escaped in double quotes. The files are encoded in UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es Windows\n",
      " El nÂ£mero de serie del volumen es: 55D7-D790\n",
      "\n",
      " Directorio de C:\\Users\\Usuario\\Desktop\\Pyspark-demo\\Data wrangling\\movielens\\ml-25m\n",
      "\n",
      "12/10/2020  12:23    <DIR>          .\n",
      "12/10/2020  12:23    <DIR>          ..\n",
      "12/10/2020  12:23       435.164.157 genome-scores.csv\n",
      "12/10/2020  12:23            18.103 genome-tags.csv\n",
      "12/10/2020  12:23         1.368.578 links.csv\n",
      "12/10/2020  12:23         3.038.099 movies.csv\n",
      "12/10/2020  12:23       678.260.987 ratings.csv\n",
      "12/10/2020  12:23            10.460 README.txt\n",
      "12/10/2020  12:23        38.810.332 tags.csv\n",
      "               7 archivos  1.156.670.716 bytes\n",
      "               2 dirs  787.255.750.656 bytes libres\n"
     ]
    }
   ],
   "source": [
    "! dir movielens\\ml-25m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that we have 6 csv files at our disposal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to start by reading ratings.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.format(\"csv\").option(\"delimiter\", \",\"\n",
    "                                         ).option(\"ESCAPE quote\", '\"'\n",
    "                                                 ). option(\"header\",True\n",
    "                                                          ).option(\"encoding\", \"UTF-8\").load(\"movielens/ml-25m/ratings.csv\"\n",
    "                                                                                            ).coalesce(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to partition the file into 4 chunks to improve performance (pay attention the last chained command **coalesce**), but when you are working on a cluster partition the file into number of nodes that you have in your cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at its first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    296|   5.0|1147880044|\n",
      "|     1|    306|   3.5|1147868817|\n",
      "|     1|    307|   5.0|1147868828|\n",
      "|     1|    665|   5.0|1147878820|\n",
      "|     1|    899|   3.5|1147868510|\n",
      "|     1|   1088|   4.0|1147868495|\n",
      "|     1|   1175|   3.5|1147868826|\n",
      "|     1|   1217|   3.5|1147878326|\n",
      "|     1|   1237|   5.0|1147868839|\n",
      "|     1|   1250|   4.0|1147868414|\n",
      "|     1|   1260|   3.5|1147877857|\n",
      "|     1|   1653|   4.0|1147868097|\n",
      "|     1|   2011|   2.5|1147868079|\n",
      "|     1|   2012|   2.5|1147868068|\n",
      "|     1|   2068|   2.5|1147869044|\n",
      "|     1|   2161|   3.5|1147868609|\n",
      "|     1|   2351|   4.5|1147877957|\n",
      "|     1|   2573|   4.0|1147878923|\n",
      "|     1|   2632|   5.0|1147878248|\n",
      "|     1|   2692|   5.0|1147869100|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the time stamp are unix (number of seconds since 1 january 1970) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I am going to convert timestamp to human readable timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
